{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# from dataclasses import dataclass, field\n",
    "# \n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import typing as tp\n",
    "# import jijmodeling as jm\n",
    "# import pathlib\n",
    "# import uuid\n",
    "# \n",
    "# @dataclass\n",
    "# class DataNode:\n",
    "#     data: tp.Any\n",
    "#     name: str | None = None\n",
    "#     operator: FunctionNode | None = None\n",
    "# \n",
    "# \n",
    "# class FunctionNode:\n",
    "#     name: str | None = None\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#     ) -> None:\n",
    "#         self.inputs = []\n",
    "# \n",
    "#     def apply(self, inputs: list[DataNode], **kwargs: tp.Any) -> DataNode:\n",
    "#         self.inputs += inputs\n",
    "#         return self.operate(inputs, **kwargs)\n",
    "# \n",
    "#     def operate(self, inputs: list[DataNode], **kwargs: tp.Any) -> DataNode:\n",
    "#         raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT_RESULT_DIR = \"./.jb_results\"\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class ID(DataNode):\n",
    "#     data: str | uuid.UUID = field(default_factory=uuid.uuid4)\n",
    "# \n",
    "#     def __post_init__(self):\n",
    "#         self.data = str(self.data)\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Date(DataNode):\n",
    "#     data: str | pd.Timestamp = field(default_factory=pd.Timestamp.now)\n",
    "#     name: str = \"timestamp\"\n",
    "# \n",
    "#     def __post_init__(self):\n",
    "#         if isinstance(self.data, str):\n",
    "#             self.data = pd.Timestamp(self.data)\n",
    "# \n",
    "# \n",
    "# class Min(FunctionNode):\n",
    "#     name = \"min\"\n",
    "# \n",
    "#     def operate(self, inputs: list[Array]) -> DataNode:\n",
    "#         data = inputs[0].data.min()\n",
    "#         name = inputs[0].name + f\"_{self.name}\" if inputs[0].name else None\n",
    "#         node = DataNode(data=data, name=name, operator=self)\n",
    "#         return node\n",
    "# \n",
    "# \n",
    "# class Max(FunctionNode):\n",
    "#     name = \"max\"\n",
    "# \n",
    "#     def operate(self, inputs: list[Array]) -> DataNode:\n",
    "#         data = inputs[0].data.max()\n",
    "#         name = inputs[0].name + f\"_{self.name}\" if inputs[0].name else None\n",
    "#         node = DataNode(data=data, name=name, operator=self)\n",
    "#         return node\n",
    "# \n",
    "# \n",
    "# class Mean(FunctionNode):\n",
    "#     name = \"mean\"\n",
    "# \n",
    "#     def operate(self, inputs: list[Array]) -> DataNode:\n",
    "#         data = inputs[0].data.mean()\n",
    "#         name = inputs[0].name + f\"_{self.name}\" if inputs[0].name else None\n",
    "#         node = DataNode(data=data, name=name, operator=self)\n",
    "#         return node\n",
    "# \n",
    "# \n",
    "# class Std(FunctionNode):\n",
    "#     name = \"std\"\n",
    "# \n",
    "#     def operate(self, inputs: list[Array]) -> DataNode:\n",
    "#         data = inputs[0].data.std()\n",
    "#         name = inputs[0].name + f\"_{self.name}\" if inputs[0].name else None\n",
    "#         node = DataNode(data=data, name=name, operator=self)\n",
    "#         return node\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Array(DataNode):\n",
    "#     data: np.ndarray\n",
    "# \n",
    "#     def min(self) -> DataNode:\n",
    "#         return Min().apply([self])\n",
    "# \n",
    "#     def max(self) -> DataNode:\n",
    "#         return Max().apply([self])\n",
    "# \n",
    "#     def mean(self) -> DataNode:\n",
    "#         return Mean().apply([self])\n",
    "# \n",
    "#     def std(self) -> DataNode:\n",
    "#         return Std().apply([self])\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Energy(Array):\n",
    "#     name: str = \"energy\"\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Objective(Array):\n",
    "#     name: str = \"objective\"\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class ConstraintViolation(Array):\n",
    "#     def __post_init__(self):\n",
    "#         if self.name is None:\n",
    "#             raise NameError(\"Attribute 'name' is None. Please set a name.\")\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class SampleSet(DataNode):\n",
    "#     data: jm.SampleSet\n",
    "# \n",
    "# \n",
    "# class RecordFactory(FunctionNode):\n",
    "#     name = \"record\"\n",
    "# \n",
    "#     def operate(self, inputs: list[DataNode], name: str | None = None) -> Record:\n",
    "#         data = pd.Series({node.name: node.data for node in inputs})\n",
    "#         return Record(data, name=name, operator=self)\n",
    "# \n",
    "# \n",
    "# class TableFactory(FunctionNode):\n",
    "#     name = \"table\"\n",
    "# \n",
    "#     def operate(self, inputs: list[Record], name: str | None = None) -> Table:\n",
    "#         data = pd.DataFrame({node.name: node.data for node in inputs})\n",
    "#         return Table(data, name=name, operator=self)\n",
    "# \n",
    "# \n",
    "# class ArtifactFactory(FunctionNode):\n",
    "#     name = \"artifact\"\n",
    "# \n",
    "#     def operate(self, inputs: list[Record], name: str | None = None) -> Artifact:\n",
    "#         data = {node.name: node.data.to_dict() for node in inputs}\n",
    "#         return Artifact(data, name=name, operator=self)\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Record(DataNode):\n",
    "#     data: pd.Series = field(default_factory=lambda: pd.Series(dtype=\"object\"))\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Table(DataNode):\n",
    "#     data: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "# \n",
    "#     def append(self, record: Record, axis: tp.Literal[0, 1] = 0) -> Table:\n",
    "#         table = TableFactory().apply([record])\n",
    "#         return Concat().apply([self, table], axis=axis)\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Artifact(DataNode):\n",
    "#     data: dict = field(default_factory=dict)\n",
    "# \n",
    "# \n",
    "# class Concat(FunctionNode):\n",
    "#     name = \"concat\"\n",
    "# \n",
    "#     def operate(\n",
    "#         self, inputs: list[Table] | list[Artifact], name=None, axis: tp.Literal[0, 1] = 0\n",
    "#     ) -> Table | Artifact:\n",
    "#         dtype = type(inputs[0])\n",
    "#         if not all([isinstance(node, dtype) for node in inputs]):\n",
    "#             raise TypeError(\n",
    "#                 \"Type of elements of 'inputs' must be unified with either 'Table' or 'Artifact'.\"\n",
    "#             )\n",
    "# \n",
    "#         if isinstance(inputs[0], Artifact):\n",
    "#             data = {node.name: node.data for node in inputs}\n",
    "#             return Artifact(data=data, name=name, operator=self)\n",
    "#         elif isinstance(inputs[0], Table):\n",
    "#             data = pd.concat(\n",
    "#                 [node.data for node in inputs if isinstance(node, Table)], axis=axis\n",
    "#             )\n",
    "#             return Table(data=data, name=name, operator=self)\n",
    "#         else:\n",
    "#             raise TypeError(f\"'{inputs[0].__class__.__name__}' type is not supported.\")\n",
    "# \n",
    "# \n",
    "# @dataclass\n",
    "# class Experiment(DataNode):\n",
    "#     data: tuple = ()\n",
    "# \n",
    "#     def __post_init__(self):\n",
    "#         if not self.data:\n",
    "#             self.data = (Table(), Artifact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import typing as tp\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DN:\n",
    "    data: tp.Any\n",
    "    name: str | None = None\n",
    "\n",
    "    @property\n",
    "    def dtype(self) -> type:\n",
    "        return type(self.data)\n",
    "\n",
    "\n",
    "d = DN([1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.functions\n",
    "import pandas as pd\n",
    "from pandas.core import frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import jijbench as jb\n",
    "import numpy as np\n",
    "\n",
    "from jijbench.node.base import DataNode, FunctionNode\n",
    "from jijbench.functions.math import Min\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = jb.Array(np.array([1, 2, 3]))\n",
    "f: FunctionNode[jb.Array, jb.Array] = Min()\n",
    "res = array.apply(f)\n",
    "res.operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id    ID(data='963fccd9-f449-463b-96dc-fc4de1474a7d'...\n",
       "id    ID(data='963fccd9-f449-463b-96dc-fc4de1474a7d'...\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory = jb.functions.RecordFactory()\n",
    "\n",
    "inputs = [jb.ID(name=\"id\"), jb.Date(), jb.Array(np.arange(5))]\n",
    "record = factory(inputs)\n",
    "\n",
    "record = pd.concat([record.data, record.data])\n",
    "record[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "\n",
    "a = A()\n",
    "a.__class__.__name__\n",
    "\n",
    "def func(x=[]):\n",
    "    x += [1]\n",
    "    return x\n",
    "\n",
    "print(func())\n",
    "(func())\n",
    "print(a)\n",
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat\n",
    "\n",
    "def f():\n",
    "    return 1\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class A(metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def f(self):\n",
    "        pass\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self, x) -> None:\n",
    "        self.x = x\n",
    "    \n",
    "    def f(self):\n",
    "        print(f\"x: {self.x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = B([1])\n",
    "\n",
    "c = type(b)(b.x)\n",
    "c.x += [2]\n",
    "b.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing as tp\n",
    "\n",
    "x = 1\n",
    "x = tp.cast(float, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1])\n",
    "x.copy()\n",
    "type(x)\n",
    "\n",
    "np.ndarray\n",
    "np._ArrayOrScalarCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140064391932992\n",
      "140064215154544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([1])\n",
    "print(id(df))\n",
    "print(id(df.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dataframe__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_add_numeric_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_append',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_box_col_values',\n",
       " '_can_fast_transpose',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_combine_frame',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_dispatch_frame_op',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_from_arrays',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_column_array',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_copy',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_iset_item',\n",
       " '_iset_item_mgr',\n",
       " '_iset_not_inplace',\n",
       " '_item_cache',\n",
       " '_iter_column_arrays',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_needs_reindex_multi',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reduce_axis1',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_rename',\n",
       " '_replace_columnwise',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_series',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_item_frame_value',\n",
       " '_set_item_mgr',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isetitem',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_orc',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'to_xml',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "T = tp.TypeVar(\"T\")\n",
    "\n",
    "def first(xs: list[T]) -> T:\n",
    "    return xs[0]\n",
    "\n",
    "x = first([1.0, 2.0, 3, \"4\"])\n",
    "\n",
    "\n",
    "class A:\n",
    "    _typ = \"T\"\n",
    "    \n",
    "    def f(self, x: T) -> T:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    def g(self, x: T) -> T:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = A()\n",
    "\n",
    "getattr(a, \"a\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import jijbench as jb\n",
    "from jijbench.node.base import DataNode\n",
    "\n",
    "t = jb.Table(pd.DataFrame())\n",
    "a = jb.Any(1, \"a\")\n",
    "\n",
    "isinstance(a, DataNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ABCBase"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"ABCBase\", (type, ), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pandas_abc_type(name, attr, comp):\n",
    "    def _check(inst):\n",
    "        return getattr(inst, attr, \"_typ\") in comp\n",
    "\n",
    "    # https://github.com/python/mypy/issues/1006\n",
    "    # error: 'classmethod' used with a non-method\n",
    "    @classmethod  # type: ignore[misc]\n",
    "    def _instancecheck(cls, inst) -> bool:\n",
    "        return _check(inst) and not isinstance(inst, type)\n",
    "\n",
    "    @classmethod  # type: ignore[misc]\n",
    "    def _subclasscheck(cls, inst) -> bool:\n",
    "        # Raise instead of returning False\n",
    "        # This is consistent with default __subclasscheck__ behavior\n",
    "        if not isinstance(inst, type):\n",
    "            raise TypeError(\"issubclass() arg 1 must be a class\")\n",
    "\n",
    "        return _check(inst)\n",
    "\n",
    "    dct = {\"__instancecheck__\": _instancecheck, \"__subclasscheck__\": _subclasscheck}\n",
    "    meta = type(\"ABCBase\", (type,), dct)\n",
    "    return meta(name, (), dct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ArtifactBase"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import typing as tp\n",
    "from typing import Type\n",
    "import jijbench as jb\n",
    "\n",
    "if tp.TYPE_CHECKING:\n",
    "    from jijbench.data.mapping import Artifact\n",
    "\n",
    "meta = type(\"Base\", (type, ), {})\n",
    "t = meta(\"Artifact\", (), {})\n",
    "AT = tp.cast(\"Artifact\", t)\n",
    "\n",
    "t2 = create_pandas_abc_type(\"ArtifactBase\", \"_typ\", (\"arifact\", ))\n",
    "AT2 = tp.cast(\"Type[Artifact]\", t2)\n",
    "\n",
    "obj = jb.Artifact({}, \"a\")\n",
    "isinstance(obj, AT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Artifact"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = type(obj.__class_, (type, ), {})\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ArtifactBase"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_typ',\n",
       " 'f',\n",
       " 'g']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = A()\n",
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(AT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Type[Artifact]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jijbench.data.mapping.Artifact"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Type[Artifact]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(t, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Type[Artifact]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = create_pandas_abc_type(\"T\", \"_typ\", (\"T\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__instancecheck__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasscheck__',\n",
       " '__subclasshook__',\n",
       " '__weakref__']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(T())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataframe'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df._typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.core.dtypes.generic import ABCDataFrame\n",
    "\n",
    "isinstance(df, ABCDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m meta\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"
     ]
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "{'x': 1}\n",
      "{'x': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 1, 'y': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x=[]):\n",
    "    return x\n",
    "\n",
    "x = f()\n",
    "x += [1]\n",
    "\n",
    "# print(f(x=[1, 2]))\n",
    "print(f())\n",
    "\n",
    "class A:\n",
    "    def __init__(self, x={}):\n",
    "        self.x = x\n",
    "\n",
    "a = A()\n",
    "a.x.update({\"x\": 1})\n",
    "print(a.x)\n",
    "print()\n",
    "\n",
    "a = A()\n",
    "print(a.x)\n",
    "a.x.update({\"y\": 2})\n",
    "a.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import typing as tp\n",
    "from typing_extensions import TypeAlias\n",
    "\n",
    "T = tp.TypeVar(\"T\", bound=A)\n",
    "S = tp.TypeVar(\"S\", bound=A)\n",
    "\n",
    "ListType: TypeAlias = tp.Union[list[int],list[float]]\n",
    "\n",
    "class A:\n",
    "    def __init__(self, b: B):\n",
    "        self.b = b\n",
    "\n",
    "class AB(A):\n",
    "    pass\n",
    "\n",
    "class B(tp.Generic[T, S]):\n",
    "    def f(self, x: T) -> S:\n",
    "        a = x[0]\n",
    "        return a\n",
    "\n",
    "\n",
    "int == int\n",
    "tp.Union[int, str] == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import copy\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing as tp\n",
    "import inspect\n",
    "import itertools\n",
    "import jijmodeling as jm\n",
    "import pathlib\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from jijbench.exceptions import SolverFailedError\n",
    "class SolverFailedError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "DNodeInType = tp.TypeVar(\"DNodeInType\", bound=\"DataNode\", covariant=True)\n",
    "DNodeOutType = tp.TypeVar(\"DNodeOutType\", bound=\"DataNode\", covariant=True)\n",
    "\n",
    "DEFAULT_RESULT_DIR = pathlib.Path(\"./.jb_results\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataNode:\n",
    "    data: tp.Any\n",
    "    name: str | None = None\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.operator: FunctionNode[DataNode, DataNode] | None = None\n",
    "\n",
    "\n",
    "\n",
    "class FunctionNode(tp.Generic[DNodeInType, DNodeOutType]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str | None = None\n",
    "    ) -> None:\n",
    "        self._name = name\n",
    "        self.inputs: list[DataNode] = []\n",
    "\n",
    "    def __call__(self, inputs: list[DNodeInType], **kwargs: tp.Any) -> DNodeOutType:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str | None:\n",
    "        return self._name\n",
    "\n",
    "    def apply(self, inputs: list[DNodeInType], **kwargs: tp.Any) -> DNodeOutType:\n",
    "        self.inputs += inputs\n",
    "        node = self(inputs, **kwargs)\n",
    "        node.operator = self\n",
    "        return node\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ID(DataNode):\n",
    "    data: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.data = str(self.data)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Date(DataNode):\n",
    "    data: str | pd.Timestamp = field(default_factory=pd.Timestamp.now)\n",
    "    name: str = \"timestamp\"\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if isinstance(self.data, str):\n",
    "            self.data = pd.Timestamp(self.data)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Value(DataNode):\n",
    "    data: int | float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Array(DataNode):\n",
    "    data: np.ndarray\n",
    "    name: str\n",
    "\n",
    "    def min(self) -> Array:\n",
    "        return Min().apply([self])\n",
    "\n",
    "    def max(self) -> Array:\n",
    "        return Max().apply([self])\n",
    "\n",
    "    def mean(self) -> Array:\n",
    "        return Mean().apply([self])\n",
    "\n",
    "    def std(self) -> Array:\n",
    "        return Std().apply([self])\n",
    "\n",
    "\n",
    "class Min(FunctionNode[\"Array\", \"Array\"]):\n",
    "    def __call__(self, inputs: list[Array]) -> Array:\n",
    "        data = inputs[0].data.min()\n",
    "        name = inputs[0].name + f\"_{self.name}\"\n",
    "        node = Array(data=data, name=name)\n",
    "        return node\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"min\"\n",
    "\n",
    "\n",
    "class Max(FunctionNode[\"Array\", \"Array\"]):\n",
    "    def __call__(self, inputs: list[Array]) -> Array:\n",
    "        data = inputs[0].data.max()\n",
    "        name = inputs[0].name + f\"_{self.name}\"\n",
    "        node = Array(data=data, name=name)\n",
    "        return node\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"max\"\n",
    "\n",
    "\n",
    "class Mean(FunctionNode[\"Array\", \"Array\"]):\n",
    "    def __call__(self, inputs: list[Array]) -> Array:\n",
    "        data = inputs[0].data.mean()\n",
    "        name = inputs[0].name + f\"_{self.name}\"\n",
    "        node = Array(data=data, name=name)\n",
    "        return node\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"mean\"\n",
    "\n",
    "\n",
    "class Std(FunctionNode[\"Array\", \"Array\"]):\n",
    "    def __call__(self, inputs: list[Array]) -> Array:\n",
    "        data = inputs[0].data.std()\n",
    "        name = inputs[0].name + f\"_{self.name}\"\n",
    "        node = Array(data=data, name=name)\n",
    "        return node\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"std\"\n",
    "\n",
    "\n",
    "class RecordFactory(FunctionNode[\"DataNode\", \"Record\"]):\n",
    "    def __call__(self, inputs: list[DataNode], name: str | None = None, extract: bool = True) -> Record:\n",
    "        data = {}\n",
    "        for node in inputs:\n",
    "            if isinstance(node.data, jm.SampleSet) and extract:\n",
    "                data.update({n.name: n.data for n in self._to_nodes_from_sampleset(node.data)})\n",
    "            else:\n",
    "                data[node.name] = node.data\n",
    "        data = pd.Series(data)\n",
    "        return Record(data, name=name)\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"record\"\n",
    "\n",
    "    def _to_nodes_from_sampleset(self, sampleset: jm.SampleSet) -> list[DataNode]:\n",
    "        data = []\n",
    "\n",
    "        data.append(Array(np.array(sampleset.record.num_occurrences), \"num_occurrences\"))\n",
    "        data.append(Array(np.array(sampleset.evaluation.energy), \"energy\"))\n",
    "        data.append(Array(np.array(sampleset.evaluation.objective), \"objective\"))\n",
    "\n",
    "        constraint_violations = sampleset.evaluation.constraint_violations\n",
    "        if constraint_violations:\n",
    "            for k, v in constraint_violations.items():\n",
    "                data.append(Array(np.array(v), k))\n",
    "\n",
    "        data.append(Value(sum(sampleset.record.num_occurrences), \"num_samples\"))\n",
    "        data.append(Value(sum(sampleset.feasible().record.num_occurrences), \"num_feasible\"))\n",
    "\n",
    "        # TODO スキーマが変わったら修正\n",
    "        solving_time = sampleset.measuring_time.solve\n",
    "        if solving_time is None:\n",
    "            execution_time = np.nan\n",
    "            warnings.warn(\n",
    "                \"'solve' of jijmodeling.SampleSet is None. Give it if you want to evaluate automatically.\"\n",
    "            )\n",
    "        else:\n",
    "            if solving_time.solve is None:\n",
    "                execution_time = np.nan\n",
    "                warnings.warn(\n",
    "                    \"'solve' of jijmodeling.SampleSet is None. Give it if you want to evaluate automatically.\"\n",
    "                )\n",
    "            else:\n",
    "                execution_time = solving_time.solve\n",
    "        data.append(Value(execution_time, \"execution_time\"))\n",
    "        return data\n",
    "\n",
    "\n",
    "class TableFactory(FunctionNode[\"Record\", \"Table\"]):\n",
    "    def __call__(self, inputs: list[Record], name: str | None = None, index_name: str | None = None) -> Table:\n",
    "        data = pd.DataFrame({node.name: node.data for node in inputs}).T\n",
    "        data.index.name = index_name\n",
    "        return Table(data, name=name)\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"table\"\n",
    "\n",
    "\n",
    "class ArtifactFactory(FunctionNode[\"Record\", \"Artifact\"]):\n",
    "    def __call__(self, inputs: list[Record], name: str | None = None) -> Artifact:\n",
    "        data = {node.name: node.data.to_dict() for node in inputs}\n",
    "        return Artifact(data, name=name)\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"artifact\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Record(DataNode):\n",
    "    data: pd.Series = field(default_factory=lambda: pd.Series(dtype=\"object\"))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataBase(DataNode):\n",
    "    def append(self, record: Record, **kwargs: tp.Any) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _append(self, record: Record, factory: TableFactory | ArtifactFactory, **kwargs: tp.Any) -> None:\n",
    "        node = factory.apply([record], name=self.name)\n",
    "        node.operator = factory\n",
    "\n",
    "        c = Concat()\n",
    "        inputs = [copy.deepcopy(self), node]\n",
    "        c.inputs = inputs\n",
    "        self.data = c(inputs, **kwargs).data\n",
    "        self.operator = c\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Table(DataBase):\n",
    "    data: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "\n",
    "    def append(self, record: Record, axis: tp.Literal[0, 1] = 0, index_name: str | None = None, **kwargs: tp.Any) -> None:\n",
    "        self._append(record, TableFactory(), axis=axis, index_name=index_name)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Artifact(DataBase):\n",
    "    data: dict = field(default_factory=dict)\n",
    "\n",
    "    def append(self, record: Record, **kwargs: tp.Any) -> None:\n",
    "        self._append(record, ArtifactFactory(), **kwargs)\n",
    "\n",
    "\n",
    "class Concat(FunctionNode[\"DataBase\", \"DataBase\"]):\n",
    "    def __call__(\n",
    "        self,\n",
    "        inputs: list[DataBase],\n",
    "        name: str | None = None,\n",
    "        axis: tp.Literal[0, 1] = 0,\n",
    "        index_name: str | None = None\n",
    "    ) -> DataBase:\n",
    "        dtype = type(inputs[0])\n",
    "        if not all([isinstance(node, dtype) for node in inputs]):\n",
    "            raise TypeError(\n",
    "                \"Type of elements of 'inputs' must be unified with either 'Table' or 'Artifact'.\"\n",
    "            )\n",
    "\n",
    "        if isinstance(inputs[0], Artifact):\n",
    "            data = inputs[0].data.copy()\n",
    "            for node in inputs[1:]:\n",
    "                if node.name in data:\n",
    "                    data[node.name].update(node.data.copy())\n",
    "                else:\n",
    "                    data[node.name] = node.data.copy()\n",
    "            return Artifact(data=data, name=name)\n",
    "        elif isinstance(inputs[0], Table):\n",
    "            data = pd.concat(\n",
    "                [node.data for node in inputs], axis=axis\n",
    "            )\n",
    "            data.index.name = index_name\n",
    "            return Table(data=data, name=name)\n",
    "        else:\n",
    "            raise TypeError(f\"'{inputs[0].__class__.__name__}' type is not supported.\")\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"concat\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Experiment(DataBase):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: tuple[Artifact, Table] | None = None,\n",
    "            name: str | None = None,\n",
    "            autosave: bool = True,\n",
    "            savedir: str | pathlib.Path = DEFAULT_RESULT_DIR\n",
    "        ):\n",
    "        if name is None:\n",
    "            name = ID().data\n",
    "\n",
    "        if data is None:\n",
    "            data = (Artifact(), Table())\n",
    "\n",
    "        if data[0].name is None:\n",
    "            data[0].name = name\n",
    "\n",
    "        if data[1].name is None:\n",
    "            data[1].name = name\n",
    "\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.autosave = autosave\n",
    "\n",
    "        if isinstance(savedir, str):\n",
    "            savedir = pathlib.Path(savedir)\n",
    "        self.savedir = savedir\n",
    "\n",
    "    @property\n",
    "    def artifact(self) -> dict:\n",
    "        return self.data[0].data\n",
    "\n",
    "    @property\n",
    "    def table(self) -> pd.DataFrame:\n",
    "        t = self.data[1].data\n",
    "        is_tuple_index = all([isinstance(i, tuple) for i in t.index])\n",
    "        if is_tuple_index:\n",
    "            names = t.index.names if len(t.index.names) >= 2 else None\n",
    "            index = pd.MultiIndex.from_tuples(t.index, names=names)\n",
    "            t.index = index\n",
    "        return t\n",
    "\n",
    "    def __enter__(self) -> Experiment:\n",
    "        p = self.savedir / str(self.name)\n",
    "        (p / \"table\").mkdir(parents=True, exist_ok=True)\n",
    "        (p / \"artifact\").mkdir(parents=True, exist_ok=True)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exception_type, exception_value, traceback) -> None:\n",
    "        index = (self.name, self.table.index[-1])\n",
    "        self.table.rename(index={self.table.index[-1]: index}, inplace=True)\n",
    "\n",
    "        if self.autosave:\n",
    "            self.save()\n",
    "\n",
    "    def append(self, record: Record) -> None:\n",
    "        for d in self.data:\n",
    "            d.append(record, index_name=(\"experiment_id\", \"run_id\"))\n",
    "\n",
    "    def concat(self, experiment: Experiment) -> None:\n",
    "        c = Concat()\n",
    "\n",
    "        artifact = c([self.data[0], experiment.data[0]])\n",
    "        table = c([self.data[1], experiment.data[1]])\n",
    "\n",
    "        self.data = (artifact, table)\n",
    "        self.operator = c\n",
    "\n",
    "    def save(self):\n",
    "        def is_dillable(obj: tp.Any):\n",
    "            try:\n",
    "                dill.dumps(obj)\n",
    "                return True\n",
    "            except Exception:\n",
    "                return False\n",
    "\n",
    "        p = self.savedir / str(self.name) / \"table\" / \"table.csv\"\n",
    "        self.table.to_csv(p)\n",
    "\n",
    "        p = self.savedir / str(self.name) / \"artifact\" / \"artifact.dill\"\n",
    "        record_name = list(self.data[0].operator.inputs[1].data.keys())[0]\n",
    "        if p.exists():\n",
    "            with open(p, \"rb\") as f:\n",
    "                artifact = dill.load(f)\n",
    "                artifact[self.name][record_name] = {}\n",
    "        else:\n",
    "            artifact = {self.name: {record_name: {}}}\n",
    "\n",
    "        record = {}\n",
    "        for k, v in self.artifact[self.name][record_name].items():\n",
    "            if is_dillable(v):\n",
    "                record[k] = v\n",
    "            else:\n",
    "                record[k] = str(v)\n",
    "        artifact[self.name][record_name].update(record)\n",
    "\n",
    "        with open(p, \"wb\") as f:\n",
    "            dill.dump(artifact, f)\n",
    "\n",
    "\n",
    "class Solver(FunctionNode[\"DataNode\", \"Record\"]):\n",
    "    def __init__(self, function: tp.Callable) -> None:\n",
    "        super().__init__()\n",
    "        self.function = function\n",
    "\n",
    "    def __call__(self, extract: bool = True, **kwargs: tp.Any) -> Record:\n",
    "        parameters = inspect.signature(self.function).parameters\n",
    "        is_kwargs = any([p.kind == 4 for p in parameters.values()])\n",
    "        kwargs = (\n",
    "            kwargs\n",
    "            if is_kwargs\n",
    "            else {k: v for k, v in kwargs.items() if k in parameters}\n",
    "        )\n",
    "        try:\n",
    "            ret = self.function(**kwargs)\n",
    "            if not isinstance(ret, tuple):\n",
    "                ret = (ret, )\n",
    "        except Exception as e:\n",
    "            msg = f'An error occurred inside your solver. Please check implementation of \"{self.name}\". -> {e}'\n",
    "            raise SolverFailedError(msg)\n",
    "\n",
    "        solver_return_names = [f\"{self.name}_return[{i}]\" for i in range(len(ret))]\n",
    "        nodes = [DataNode(data=data, name=name) for data, name in zip(ret, solver_return_names)]\n",
    "        return RecordFactory().apply(nodes, extract=extract)\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.function.__name__\n",
    "\n",
    "\n",
    "class Benchmark(FunctionNode[\"DataNode\", \"Experiment\"]):\n",
    "    def __init__(\n",
    "            self,\n",
    "            params: dict[str, tp.Iterable[tp.Any]],\n",
    "            solver: tp.Callable | list[tp.Callable],\n",
    "            name: str | None = None,\n",
    "            autosave: bool = True,\n",
    "            savedir: str | pathlib.Path = DEFAULT_RESULT_DIR,\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        if isinstance(solver, tp.Callable):\n",
    "            self.solver = [solver]\n",
    "        else:\n",
    "            self.solver = solver\n",
    "\n",
    "        if name is None:\n",
    "            name = ID().data\n",
    "        self._name = name\n",
    "\n",
    "        self.autosave = autosave\n",
    "        self.savedir = savedir\n",
    "\n",
    "    def __call__(self, concurrent=False, extract=True) -> Experiment:\n",
    "        experiment = Experiment(name=ID().data, autosave=self.autosave, savedir=self.savedir)\n",
    "        for f in self.solver:\n",
    "            if concurrent:\n",
    "                experiment = self._run_concurrently(experiment, Solver(f))\n",
    "            else:\n",
    "                experiment = self._run_sequentially(experiment, Solver(f))\n",
    "        return experiment\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    def _run_concurrently(self, experiment: Experiment, solver: Solver) -> Experiment:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _run_sequentially(self, experiment: Experiment, solver: Solver, extract=True) -> Experiment:\n",
    "        # TODO 返り値名を変更できるようにする。\n",
    "        # solver.rename_return(ret)\n",
    "        for r in itertools.product(*self.params.values()):\n",
    "            with experiment:\n",
    "                solver_args = dict([(k, v) for k, v in zip(self.params.keys(), r)])\n",
    "                name = ID().data\n",
    "                record = solver(**solver_args, extract=extract)\n",
    "                record.name = name\n",
    "                experiment.append(record)\n",
    "\n",
    "                # TODO 入力パラメータをtableで保持する\n",
    "                # params = (dict([(k, v) for k, v in zip(self.params.keys(), r)]))\n",
    "                # params = RecordFactory().apply(params)\n",
    "                # params.name = name\n",
    "                # experiment.append(record)\n",
    "        return experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(x, y):\n",
    "    jm_sampleset_dict = {\n",
    "        \"record\": {\n",
    "            \"solution\": {\n",
    "                \"x\": [\n",
    "                    (([0, 1], [0, 1]), [1, 1], (2, 2)),\n",
    "                    (([0, 1], [1, 0]), [1, 1], (2, 2)),\n",
    "                    (([], []), [], (2, 2)),\n",
    "                    (([0, 1], [0, 0]), [1, 1], (2, 2)),\n",
    "                ]\n",
    "            },\n",
    "            \"num_occurrences\": [4, 3, 2, 1],\n",
    "        },\n",
    "        \"evaluation\": {\n",
    "            \"energy\": [3.0, 24.0, 0.0, 20.0],\n",
    "            \"objective\": [3.0, 24.0, 0.0, 17.0],\n",
    "            \"constraint_violations\": {\n",
    "                \"onehot1\": [0.0, 0.0, 2.0, 0.0],\n",
    "                \"onehot2\": [0.0, 0.0, 2.0, 2.0],\n",
    "            },\n",
    "            \"penalty\": {},\n",
    "        },\n",
    "        \"measuring_time\": {\"solve\": None, \"system\": None, \"total\": None},\n",
    "    }\n",
    "    jm_sampleset = jm.SampleSet.from_serializable(jm_sampleset_dict)\n",
    "    solving_time = jm.SolvingTime(\n",
    "        **{\"preprocess\": 1.0, \"solve\": 1.0, \"postprocess\": 1.0}\n",
    "    )\n",
    "    jm_sampleset.measuring_time.solve = solving_time\n",
    "    return jm_sampleset, x, y\n",
    "\n",
    "\n",
    "bench = Benchmark(\n",
    "    params={\"x\": range(3), \"y\": range(3)},\n",
    "    solver=[sample_model]\n",
    ")\n",
    "result = bench()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "tp.MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.data[0].operator.inputs[0].operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jijmodeling2 as jm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1():\n",
    "    return 1\n",
    "\n",
    "def f2():\n",
    "    return 1, \"a\", 3.0\n",
    "\n",
    "def f3(x, y):\n",
    "    return x * 2, y / 2\n",
    "\n",
    "s1 = Solver(f1)\n",
    "ret = s1()\n",
    "\n",
    "s2 = Solver(f2)\n",
    "ret = s2()\n",
    "ret.data\n",
    "\n",
    "s3 = Solver(f3)\n",
    "ret = s3(x=2, y=3)\n",
    "print(ret.data)\n",
    "print()\n",
    "\n",
    "table = TableFactory()([ret])\n",
    "table.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (0, 1)\n",
    "x[0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"a\": {\"i\": 0}}\n",
    "y = {\"a\": {\"sss\": \"ttt\"}}\n",
    "\n",
    "if \"a\" in x:\n",
    "    x[\"a\"].update(y[\"a\"])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jijmodeling as jm\n",
    "\n",
    "def sample_model(x, y):\n",
    "    jm_sampleset_dict = {\n",
    "        \"record\": {\n",
    "            \"solution\": {\n",
    "                \"x\": [\n",
    "                    (([0, 1], [0, 1]), [1, 1], (2, 2)),\n",
    "                    (([0, 1], [1, 0]), [1, 1], (2, 2)),\n",
    "                    (([], []), [], (2, 2)),\n",
    "                    (([0, 1], [0, 0]), [1, 1], (2, 2)),\n",
    "                ]\n",
    "            },\n",
    "            \"num_occurrences\": [4, 3, 2, 1],\n",
    "        },\n",
    "        \"evaluation\": {\n",
    "            \"energy\": [3.0, 24.0, 0.0, 20.0],\n",
    "            \"objective\": [3.0, 24.0, 0.0, 17.0],\n",
    "            \"constraint_violations\": {\n",
    "                \"onehot1\": [0.0, 0.0, 2.0, 0.0],\n",
    "                \"onehot2\": [0.0, 0.0, 2.0, 2.0],\n",
    "            },\n",
    "            \"penalty\": {},\n",
    "        },\n",
    "        \"measuring_time\": {\"solve\": None, \"system\": None, \"total\": None},\n",
    "    }\n",
    "    jm_sampleset = jm.SampleSet.from_serializable(jm_sampleset_dict)\n",
    "    solving_time = jm.SolvingTime(\n",
    "        **{\"preprocess\": 1.0, \"solve\": 1.0, \"postprocess\": 1.0}\n",
    "    )\n",
    "    jm_sampleset.measuring_time.solve = solving_time\n",
    "    return jm_sampleset, x, y\n",
    "\n",
    "e = Experiment(name=\"test\")\n",
    "print(\"start\")\n",
    "print(e.data[0])\n",
    "print(e.data[0].data)\n",
    "print()\n",
    "\n",
    "for x in range(3):\n",
    "    for y in range(3):\n",
    "        with e:\n",
    "            solver = Solver(sample_model)\n",
    "            record = solver(x=x, y=y)\n",
    "            record.name = ID().data\n",
    "            e.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.data[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.MultiIndex.from_tuples(e.table.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([1, 2, 3])\n",
    "len(df.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ((\"x\", 0), (\"x\", 1), (\"y\", 0), (\"y\", 1))\n",
    "df = pd.DataFrame([0, 1, 2, 3])\n",
    "df.index = pd.MultiIndex.from_tuples(index, names=None)\n",
    "df2 = df.reset_index()\n",
    "df2.index.names = [\"a\"]\n",
    "df3 = df2.rename(index={3: (5,)})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = Experiment()\n",
    "e1.data[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.data[0].operator.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.data[1].operator.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pathlib\n",
    "\n",
    "def func():\n",
    "    def inner():\n",
    "        return 1\n",
    "\n",
    "    return inner\n",
    "\n",
    "p = pathlib.Path(\"./test.dill\")\n",
    "\n",
    "with open(p, \"wb\") as f:\n",
    "    dill.dump(func, f)\n",
    "\n",
    "dill.dumps(lambda x: x ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pathlib\n",
    "\n",
    "p = pathlib.Path(\"./test.dill\")\n",
    "\n",
    "with open(p, \"rb\") as f:\n",
    "    obj = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "def func():\n",
    "    def inner():\n",
    "        return 1\n",
    "\n",
    "    return inner\n",
    "\n",
    "p = pathlib.Path(\"./test.pkl\")\n",
    "\n",
    "with open(p, \"wb\") as f:\n",
    "    pickle.dump(func, f)\n",
    "\n",
    "try:\n",
    "    f = lambda x: x ** 2\n",
    "    pickle.dumps(f)\n",
    "except Exception:\n",
    "    print(\"False\")\n",
    "    print(f)\n",
    "    print(str(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.dumps(\"a\")\n",
    "b = pickle.dumps(\"b\")\n",
    "\n",
    "\n",
    "with open(\"test.pkl\", \"wb\") as f:\n",
    "    f.write(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dumps(\"a\" + \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "p = pathlib.Path(\"./test.pkl\")\n",
    "\n",
    "with open(p, \"rb\") as f:\n",
    "    obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(\".\")\n",
    "df = pd.DataFrame([1])\n",
    "df.to_csv(p / \"table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = e.savedir / \"test\" /\"table\"\n",
    "p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.table.to_csv(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(\".\") / \"table2.csv\"\n",
    "p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table()\n",
    "table.append(record, axis=1)\n",
    "table.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = TableFactory().apply([record])\n",
    "table.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.table.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.table.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.artifact.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = tp.TypeVar(\"T1\")\n",
    "T2 = tp.TypeVar(\"T2\", bound=float)\n",
    "\n",
    "class A(tp.Generic[T1, T2]):\n",
    "    def f(self, x: T1) -> T2:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "class B(A[int, float]):\n",
    "    def f(self, x: int) -> float:\n",
    "        return float(x)\n",
    "    \n",
    "b = B()\n",
    "b.f(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = Array(np.arange(10))\n",
    "isinstance(array, DataNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = ID()\n",
    "print(i.data)\n",
    "print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = Experiment()\n",
    "e0.data[0].data[\"a\"] = [0, 1, 2]\n",
    "e0.data\n",
    "\n",
    "e0 = Experiment()\n",
    "e0.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "a.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = DataNode(0, name=\"d0\")\n",
    "d1 = DataNode(1, name=\"d1\")\n",
    "d2 = DataNode(2, name=\"d2\")\n",
    "\n",
    "r0 = RecordFactory()([d0, d1], name=\"new r0\")\n",
    "r1 = RecordFactory()([d0, d2], name=\"new r1\")\n",
    "r1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = Table(pd.DataFrame([0, 1], index=[\"d0\", \"d1\"], columns=[\"a\"]))\n",
    "t1 = Table(pd.DataFrame([2, 3], index=[\"d0\", \"d1\"], columns=[\"b\"]))\n",
    "tc = Concat()([t0, t1], axis=1)\n",
    "\n",
    "tc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.append(r1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ArtifactFactory().apply([r0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = Artifact({\"a\": 0, \"b\": 1}, name=ID().data)\n",
    "a1 = Artifact({\"c\": 0, \"d\": 1}, name=ID().data)\n",
    "\n",
    "print(\"aaaaa\")\n",
    "print(a0.data)\n",
    "print(id(a0))\n",
    "print()\n",
    "\n",
    "print(\"bbbbb\")\n",
    "a0.append(r1)\n",
    "print(a0.data)\n",
    "print(id(a0))\n",
    "print()\n",
    "\n",
    "print(a0.operator.inputs[0].data)\n",
    "print(id(a0.operator.inputs[0].data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "b = a.copy()\n",
    "print(id(a))\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acopy = a0.copy()\n",
    "print(acopy)\n",
    "print(id(acopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a0.operator.inputs[0])\n",
    "print(id(a0.operator.inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = Concat()([a0, a1])\n",
    "print(ac.data)\n",
    "print(a0.data)\n",
    "print(a1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df.copy()\n",
    "\n",
    "n = np.array(1)\n",
    "n.copy()\n",
    "\n",
    "from numpy import array_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ([1], )\n",
    "print(x)\n",
    "print(id(x[0]))\n",
    "\n",
    "y = (x[0], )\n",
    "print(y)\n",
    "print(id(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "\n",
    "x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = object.__new__(DataNode)\n",
    "dn.__init__(1)\n",
    "dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, x: int | None = None) -> None:\n",
    "        self.x = x\n",
    "        \n",
    "    def f(self):\n",
    "        obj = super().__new__(self.__class__)\n",
    "        obj.__init__()\n",
    "        return obj\n",
    "\n",
    "\n",
    "\n",
    "a = A(1)\n",
    "print(a.x)\n",
    "obj1 = object.__new__(a.__class__)\n",
    "obj2 = object.__new__(A)\n",
    "print(obj1)\n",
    "print(obj2)\n",
    "# print(a.__class__)\n",
    "# print(A)\n",
    "a2 = a.f()\n",
    "print(a2.x)\n",
    "print(a.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Array(np.arange(10))\n",
    "m = data.min()\n",
    "print(m)\n",
    "if m.operator is not None:\n",
    "    print(m.operator.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0.operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tp.overload\n",
    "def func(x: int) -> int:\n",
    "    ...\n",
    "\n",
    "@tp.overload\n",
    "def func(x: float) -> float:\n",
    "    ...\n",
    "\n",
    "def func(x: int | float) -> int | float:\n",
    "    if isinstance(x, int):\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "func(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Record()\n",
    "r.data[\"a\"] = 1\n",
    "r.data\n",
    "\n",
    "r1 = Record()\n",
    "r1.data\n",
    "\n",
    "r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "x1 = {\"a\": 1}\n",
    "# x.update(x1)\n",
    "x.get(\"b\", {}).update(x1)\n",
    "# x = {}.update(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ():\n",
    "    print(\"a\")\n",
    "else:\n",
    "    print(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "\n",
    "class B(A):\n",
    "    pass\n",
    "\n",
    "def func() -> A:\n",
    "    return B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = Array(np.arange(10))\n",
    "print(array.data)\n",
    "mi = array.min()\n",
    "if mi.operator is not None:\n",
    "    print(mi.operator.inputs[0])\n",
    "    \n",
    "print(array.min())\n",
    "print(array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = DataNode(pd.Series([0, 1, 2]), name=\"a\")\n",
    "d1 = DataNode(pd.Series([2, 3, 4]), name=\"b\")\n",
    "\n",
    "x = {d0.name: d0.data, d1.name: d1.data}\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class A:\n",
    "    x: int\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.y = None\n",
    "        \n",
    "    def f(self):\n",
    "        self.y += 1\n",
    "        \n",
    "a = A(1)\n",
    "a.y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jijzept as jz\n",
    "import jijmodeling as jm\n",
    "\n",
    "sampler = jz.JijSASampler(config=\"/home/d/.jijzept/config.toml\")\n",
    "\n",
    "problem = jm.Problem(\"sample\")\n",
    "x = jm.Binary(\"x\", 5)\n",
    "problem += x[:]\n",
    "problem += jm.Constraint(\"onehot\", x[:] == 1)\n",
    "\n",
    "res = sampler.sample_model(problem, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.feasible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id0 = ID(name=\"benchmark_id\")\n",
    "energy = Energy(np.array(res.evaluation.energy))\n",
    "objective = Objective(np.array(res.evaluation.objective))\n",
    "if res.evaluation.constraint_violations is not None:\n",
    "    const_name, const_values  = list(res.evaluation.constraint_violations.items())[0]\n",
    "    constraint_violation = ConstraintViolation(np.array(const_values), const_name)\n",
    "else:\n",
    "    constraint_violation = ConstraintViolation()\n",
    "\n",
    "print(energy)\n",
    "print(objective)\n",
    "print(constraint_violation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = Record(\n",
    "    name=id0.data,\n",
    "    children=[id0, energy, objective, constraint_violation]\n",
    ")\n",
    "record.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table(children=[record])\n",
    "table.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append(record)\n",
    "table.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = Artifact(children=[record])\n",
    "artifact.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = ID(name=\"benchmark_id\")\n",
    "record2 = Record(\n",
    "    name=id1.data,\n",
    "    children=[id1, energy, objective, constraint_violation]\n",
    ")\n",
    "artifact.append(record2)\n",
    "artifact.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id0)\n",
    "print(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.append(record)\n",
    "experiment.append(record2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experiment.table.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.table.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.table.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(\"./a\")\n",
    "(p / \"b\").mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(\"2022-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayVisitor:\n",
    "    def min(self, array: Array):\n",
    "        return float(array.data.min())\n",
    "    \n",
    "\n",
    "array = Array(np.arange(10))\n",
    "array.accept_min(ArrayVisitor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.variable import Variable, VariableNode\n",
    "from chainer.function_node import FunctionNode\n",
    "from chainer.function import FunctionAdapter\n",
    "\n",
    "a = Variable(np.array(10.0), name=\"a\")\n",
    "x = Variable(np.array(1.0), name=\"x\")\n",
    "y = Variable(np.array(2.0), name=\"y\")\n",
    "z = a * x + y\n",
    "\n",
    "z.backward(retain_grad=True)\n",
    "\n",
    "print(z)\n",
    "print(z.node)\n",
    "print(\"=======\")\n",
    "print(z.node.creator.inputs)\n",
    "print(z.node.creator.inputs[0].data)\n",
    "print(z.node.creator.inputs[0].name)\n",
    "print(z.node.creator.inputs[1].data)\n",
    "print(z.node.creator.inputs[1].name)\n",
    "print(\"@@@@@@@@@@\")\n",
    "print(z.node.creator.inputs[0].creator.inputs[0].data)\n",
    "print(z.node.creator.inputs[0].creator.inputs[0].name)\n",
    "print(z.node.creator.inputs[0].creator.inputs[1].data)\n",
    "print(z.node.creator.inputs[0].creator.inputs[1].name)\n",
    "print(z.node.creator.inputs[1].data)\n",
    "print(z.node.creator.inputs[1].name)\n",
    "print(\"++++++++++\")\n",
    "print(z.node.creator.inputs[0].creator.inputs[0].creator)\n",
    "print(z.node.creator.inputs[0].creator.inputs[1].creator)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.functions import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
    "s2 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tn = tp.TypeVar(\"Tn\")\n",
    "\n",
    "# class FunctionNode(tp.Generic[Tn]):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         name: str | None = None, \n",
    "#         children: list[Tn] | None = None\n",
    "#     ) -> None:\n",
    "#         self._name = name``\n",
    "#         self._children = children\n",
    "#         \n",
    "#     @property\n",
    "#     def name(self) -> str | None:\n",
    "#         return self._name\n",
    "#     \n",
    "#     @property\n",
    "#     def children(self) -> list[Tn] | None:\n",
    "#         return self._children\n",
    "#     \n",
    "#     def _narrow_children_type(self) -> list[Tn]:\n",
    "#         if self.children is None:\n",
    "#             raise ValueError(\n",
    "#                 \"Value of attribute 'children' is None, which means this node has no children. Therefore, it cannot operate node futher more.\"\n",
    "#             )\n",
    "#         return self.children\n",
    "#     \n",
    "#     def append(self, node: Tn) -> None:\n",
    "#         children = self._narrow_children_type()\n",
    "#         children.append(node)\n",
    "#     \n",
    "    \n",
    "            \n",
    "# Tn = tp.TypeVar(\"Tn\", bound=\"BaseNode\")\n",
    "# \n",
    "# class BaseNode(tp.Generic[Tn]):\n",
    "#     pass\n",
    "# \n",
    "# @dataclass\n",
    "# class DataNode(BaseNode[Tn]):\n",
    "#     data: tp.Any = None\n",
    "#     name: str | None = None\n",
    "#     children: list[Tn] | None = None\n",
    "#     \n",
    "#     \n",
    "# class FunctionNode(BaseNode[Tn]):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         name: str | None = None, \n",
    "#         children: list[Tn] | None = None\n",
    "#     ) -> None:\n",
    "#         self.name = name\n",
    "#         if children is None:\n",
    "#             self.children = []\n",
    "#         else:\n",
    "#             self.children = children\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "905557cf594ca1f9a636cbb6c9a903a20426ddf60e3dad81a8eb7de86e51df55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
